{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d03f1ec8-3ca3-4edc-9c99-c6bae9177387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set JAX platform to CPU for highest matmul precision\n",
    "import os\n",
    "#os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6d71739-61a0-470d-9b17-2e4a60c21530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanchitgandhi/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import FlaxBloomForCausalLM, BloomForCausalLM, AutoTokenizer\n",
    "import numpy as np\n",
    "import torch\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9738731-61f3-49fc-86e5-0b36ee6249a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some of the weights of FlaxBloomForCausalLM were initialized in bfloat16 precision from the model checkpoint at bigscience/bigscience-small-testing:\n",
      "[('transformer', 'h', '0', 'input_layernorm', 'bias'), ('transformer', 'h', '0', 'input_layernorm', 'scale'), ('transformer', 'h', '0', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '0', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '0', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '0', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '0', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '0', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '0', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '0', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '0', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '0', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'h', '1', 'input_layernorm', 'bias'), ('transformer', 'h', '1', 'input_layernorm', 'scale'), ('transformer', 'h', '1', 'mlp', 'dense_4h_to_h', 'bias'), ('transformer', 'h', '1', 'mlp', 'dense_4h_to_h', 'kernel'), ('transformer', 'h', '1', 'mlp', 'dense_h_to_4h', 'bias'), ('transformer', 'h', '1', 'mlp', 'dense_h_to_4h', 'kernel'), ('transformer', 'h', '1', 'post_attention_layernorm', 'bias'), ('transformer', 'h', '1', 'post_attention_layernorm', 'scale'), ('transformer', 'h', '1', 'self_attention', 'dense', 'bias'), ('transformer', 'h', '1', 'self_attention', 'dense', 'kernel'), ('transformer', 'h', '1', 'self_attention', 'query_key_value', 'bias'), ('transformer', 'h', '1', 'self_attention', 'query_key_value', 'kernel'), ('transformer', 'ln_f', 'bias'), ('transformer', 'ln_f', 'scale'), ('transformer', 'word_embeddings', 'embedding'), ('transformer', 'word_embeddings_layernorm', 'bias'), ('transformer', 'word_embeddings_layernorm', 'scale')]\n",
      "You should probably UPCAST the model weights to float32 if this was not intended. See [`~FlaxPreTrainedModel.to_fp32`] for further information on how to do this.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"bigscience/bigscience-small-testing\"\n",
    "#model_id = \"bigscience/bloom-350m\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-350m\")\n",
    "\n",
    "pt_model = BloomForCausalLM.from_pretrained(model_id)\n",
    "flax_model = FlaxBloomForCausalLM.from_pretrained(model_id, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80f18a5b-2b5f-4487-b8c0-ae6302557d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "input_str = [10*\"hello this string is definitely longer\", \"Hey you\"]\n",
    "\n",
    "inputs_pt = tokenizer(input_str, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "inputs_np = tokenizer(input_str, return_tensors=\"np\", padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c07d646a-ae15-4057-ab23-8f94f40b0e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits_pt = pt_model(**inputs_pt).logits\n",
    "    logits_pt_single = pt_model(inputs_pt.input_ids[:1]).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d780c61e-696b-45e4-b47b-f85bff466710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 13:20:07.679762: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batched padded pt vs padded flax\n",
      "0.00037539005\n",
      "batched full pt vs full flax\n",
      "0.0003239885\n",
      "single pt vs flax\n",
      "0.0003239885\n",
      "single flax vs flax\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# default matmul precision (bfloat16)\n",
    "logits_fx = flax_model(**inputs_np).logits\n",
    "logits_fx_single = flax_model(inputs_np.input_ids[:1]).logits\n",
    "\n",
    "print(\"batched padded pt vs padded flax\")\n",
    "print(np.max(np.abs(logits_pt[1, :2].numpy() - np.array(logits_fx[1, :2]))))\n",
    "\n",
    "print(\"batched full pt vs full flax\")\n",
    "print(np.max(np.abs(logits_pt[0].numpy() - np.array(logits_fx[0]))))\n",
    "\n",
    "print(\"single pt vs flax\")\n",
    "print(np.max(np.abs(logits_pt_single[0].numpy() - np.array(logits_fx_single[0]))))\n",
    "\n",
    "print(\"single flax vs flax\")\n",
    "print(np.max(np.abs(np.array(logits_fx[0]) - np.array(logits_fx_single[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5b30af3-6948-453d-8810-7982c858d0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batched padded pt vs padded flax\n",
      "5.9604645e-08\n",
      "batched full pt vs full flax\n",
      "1.4901161e-07\n",
      "single pt vs flax\n",
      "1.1920929e-07\n",
      "single flax vs flax\n",
      "5.9604645e-08\n"
     ]
    }
   ],
   "source": [
    "# highest matmul precision (float32)\n",
    "with jax.default_matmul_precision('float32'):\n",
    "    logits_fx = flax_model(**inputs_np).logits\n",
    "    logits_fx_single = flax_model(inputs_np.input_ids[:1]).logits\n",
    "    \n",
    "print(\"batched padded pt vs padded flax\")\n",
    "print(np.max(np.abs(logits_pt[1, :2].numpy() - np.array(logits_fx[1, :2]))))\n",
    "\n",
    "print(\"batched full pt vs full flax\")\n",
    "print(np.max(np.abs(logits_pt[0].numpy() - np.array(logits_fx[0]))))\n",
    "\n",
    "print(\"single pt vs flax\")\n",
    "print(np.max(np.abs(logits_pt_single[0].numpy() - np.array(logits_fx_single[0]))))\n",
    "\n",
    "print(\"single flax vs flax\")\n",
    "print(np.max(np.abs(np.array(logits_fx[0]) - np.array(logits_fx_single[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0769a6da-d641-4367-9f65-2e0852c88c2b",
   "metadata": {},
   "source": [
    "## JIT the fprop and watch the magic happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80292b8d-734a-4d17-8a6c-3e3a3fd18aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def flax_model_jitted(input_ids, attention_mask=None, **kwargs):\n",
    "    return flax_model(input_ids, attention_mask=attention_mask, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34cb44ed-08b1-45c0-b52a-5975465da054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.77 s, sys: 414 ms, total: 7.18 s\n",
      "Wall time: 6.54 s\n"
     ]
    }
   ],
   "source": [
    "# microbench jit compile time for batch\n",
    "%time logits_fx = flax_model_jitted(**inputs_np).logits.block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf45ce7a-625b-47a8-acf5-a678170020eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.62 ms, sys: 718 µs, total: 3.33 ms\n",
      "Wall time: 2.93 ms\n"
     ]
    }
   ],
   "source": [
    "# microbench compiled fprop -> should be ~ms, if on the order of seconds inidicates a recompilation\n",
    "%time logits_fx = flax_model_jitted(**inputs_np).logits.block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86cd67dc-868c-42f9-88b9-814e3b06cbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.94 s, sys: 239 ms, total: 6.18 s\n",
      "Wall time: 5.85 s\n"
     ]
    }
   ],
   "source": [
    "# microbench jit compile time for single input\n",
    "%time logits_fx_single = flax_model_jitted(inputs_np.input_ids[:1]).logits.block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d244938-3d66-4a5f-8bfb-e6ed6328fb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.28 ms, sys: 559 µs, total: 2.84 ms\n",
      "Wall time: 1.39 ms\n"
     ]
    }
   ],
   "source": [
    "# microbench compiled fprop for single input -> should be ~ms, if on the order of seconds inidicates a recompilation\n",
    "%time logits_fx_single = flax_model_jitted(inputs_np.input_ids[:1]).logits.block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57134e64-16c4-4539-a4cd-5b18b86a70cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batched padded pt vs padded flax\n",
      "0.00037539005\n",
      "batched full pt vs full flax\n",
      "0.0003239885\n",
      "single pt vs flax\n",
      "0.0003239885\n",
      "single flax vs flax\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# verify correctness of jit-compiled fprop\n",
    "print(\"batched padded pt vs padded flax\")\n",
    "print(np.max(np.abs(logits_pt[1, :2].numpy() - np.array(logits_fx[1, :2]))))\n",
    "\n",
    "print(\"batched full pt vs full flax\")\n",
    "print(np.max(np.abs(logits_pt[0].numpy() - np.array(logits_fx[0]))))\n",
    "\n",
    "print(\"single pt vs flax\")\n",
    "print(np.max(np.abs(logits_pt_single[0].numpy() - np.array(logits_fx_single[0]))))\n",
    "\n",
    "print(\"single flax vs flax\")\n",
    "print(np.max(np.abs(np.array(logits_fx[0]) - np.array(logits_fx_single[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ccb1b-4ed0-4cd9-abbb-0040c2e2cf2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
