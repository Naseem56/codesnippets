{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4084e2c-1c5d-4cbc-95c6-bcd63e5c3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline, WhisperForConditionalGeneration, WhisperProcessor\n",
    "from evaluate import load\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "014e25b0-6cab-462b-9875-f4967314aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"LIUM/tedlium\", \"release3\", split=\"validation\", streaming=True)\n",
    "dataset = dataset.take(32)\n",
    "\n",
    "whisper_asr = pipeline(\n",
    "    \"automatic-speech-recognition\", model=\"openai/whisper-tiny.en\", device=0\n",
    ")\n",
    "\n",
    "whisper_asr.model.config.suppress_tokens.remove(6)\n",
    "whisper_asr.model.config.suppress_tokens.remove(12)\n",
    "\n",
    "wer_metric = load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e880a279-0d4a-45bb-83f5-5cb34d646306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(text):\n",
    "    return whisper_asr.tokenizer._normalize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f5de46-eda6-418d-9f81-60d93f9c6167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: get the column names for the datasets\n",
    "def get_text(sample):\n",
    "    if \"text\" in sample:\n",
    "        return sample[\"text\"]\n",
    "    elif \"sentence\" in sample:\n",
    "        return sample[\"sentence\"]\n",
    "    elif \"normalized_text\" in sample:\n",
    "        return sample[\"normalized_text\"]\n",
    "    elif \"transcript\" in sample:\n",
    "        return sample[\"transcript\"]\n",
    "    else:\n",
    "        raise ValueError(f\"Sample: {sample.keys()} has no transcript.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f52c8e3-59f6-4f8c-9a9e-fa888f6369c9",
   "metadata": {},
   "source": [
    "## Method 1: with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcf74a17-d631-4ada-954f-4a51848daa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_normalise(batch):\n",
    "    references = get_text(batch)\n",
    "    predictions = whisper_asr(batch[\"audio\"])\n",
    "\n",
    "    batch[\"ref\"] = [normalise(ref) for ref in references]\n",
    "    batch[\"pred\"] = [normalise(pred[\"text\"]) for pred in predictions]\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b82b86eb-3fd6-4b6d-8b52-e576a5aa0bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size for extracting references and predictions\n",
    "batch_size = 8\n",
    "\n",
    "result_set = dataset.map(\n",
    "    predict_and_normalise,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    remove_columns=dataset.features.keys(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1223a6d9-e70b-47cd-a264-42e60f3d6c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_target_text_in_range(ref):\n",
    "    if ref.strip() == \"ignore time segment in scoring\":\n",
    "        return False\n",
    "    else:\n",
    "        return ref.strip() != \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aa3a657-d23e-4967-ab99-8797eb899b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_set = result_set.filter(is_target_text_in_range, input_columns=[\"ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2ad8b7b-e56c-4ddb-b1b5-455d0c7bd7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanchit_huggingface_co/transformers/src/transformers/generation/utils.py:1387: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.2 s, sys: 1.17 s, total: 52.4 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "refs = []\n",
    "preds = []\n",
    "\n",
    "for i, sample in enumerate(result_set):\n",
    "    refs.append(sample[\"ref\"])\n",
    "    preds.append(sample[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d442d363-0d9a-498d-bfce-e023f86a1ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER:  3.95\n"
     ]
    }
   ],
   "source": [
    "wer = wer_metric.compute(references=refs, predictions=preds)\n",
    "wer = round(100 * wer, 2)\n",
    "\n",
    "print(\"WER: \", wer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fbcc33-57a3-4dde-8c52-3c42b9c49dfd",
   "metadata": {},
   "source": [
    "####Â Re-run pipeline again to remove 'warm-up' effects from datasets and cuda init:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "833e9242-dd47-43d7-b6a5-d5991886a73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.3 s, sys: 690 ms, total: 42 s\n",
      "Wall time: 6.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "refs = []\n",
    "preds = []\n",
    "\n",
    "for i, sample in enumerate(result_set):\n",
    "    refs.append(sample[\"ref\"])\n",
    "    preds.append(sample[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a820c50-2ffc-45df-8930-ebcf3048b5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER:  3.95\n"
     ]
    }
   ],
   "source": [
    "wer = wer_metric.compute(references=refs, predictions=preds)\n",
    "wer = round(100 * wer, 2)\n",
    "\n",
    "print(\"WER: \", wer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c50af2-9b06-4c9d-8fa7-d25559056b93",
   "metadata": {},
   "source": [
    "## Method 2: with processor + model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9963671-c498-4364-bc2d-202674d7cd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny.en\").to(\"cuda:1\")\n",
    "\n",
    "model.config.suppress_tokens.remove(6)\n",
    "model.config.suppress_tokens.remove(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fae69d1-19c1-487e-b89a-93f6ec30537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_normalise_2(batch):    \n",
    "    audios = [audio[\"array\"] for audio in batch[\"audio\"]]\n",
    "    references = get_text(batch)\n",
    "    input_features = processor(audios, sampling_rate=16000, return_tensors=\"pt\").input_features\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(input_features.to(\"cuda:1\"))\n",
    "    predictions = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "\n",
    "    batch[\"ref\"] = [normalise(ref) for ref in references]\n",
    "    batch[\"pred\"] = [normalise(pred) for pred in predictions]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "686fb2d0-bfc1-451c-b3cc-b39823f8539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size for extracting references and predictions\n",
    "batch_size = 8\n",
    "\n",
    "result_set_2 = dataset.map(\n",
    "    predict_and_normalise_2,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    remove_columns=dataset.features.keys(),\n",
    ")\n",
    "\n",
    "result_set_2 = result_set_2.filter(is_target_text_in_range, input_columns=[\"ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da7342e1-bf36-48b4-aa9f-332346666dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.5 s, sys: 364 ms, total: 18.8 s\n",
      "Wall time: 4.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "refs = []\n",
    "preds = []\n",
    "\n",
    "for i, sample in enumerate(result_set_2):\n",
    "    refs.append(sample[\"ref\"])\n",
    "    preds.append(sample[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3d74c16-04ab-4dc0-8ec6-999e29891774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER:  3.95\n"
     ]
    }
   ],
   "source": [
    "wer = wer_metric.compute(references=refs, predictions=preds)\n",
    "wer = round(100 * wer, 2)\n",
    "\n",
    "print(\"WER: \", wer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7661fb53-7e43-4bdb-8bc1-4a4c932914ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
