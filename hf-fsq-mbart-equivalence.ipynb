{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71c0384-3ac7-4236-a560-7d7be3e77456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 12:08:14 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n"
     ]
    }
   ],
   "source": [
    "import fairseq\n",
    "import torch\n",
    "from transformers import SpeechToSpeechModel, Wav2Vec2FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c59e1b27-3d42-4b63-bce5-be94db62c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_path = \"./pytorch_dump_folder\"\n",
    "fairseq_wav2vec2_path = \"./w2v2_mbart_LND_w_ASR.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c74a6aef-c883-42b5-90f5-61ab7149a5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 12:08:19 | INFO | fairseq.tasks.speech_to_text | dictionary size (dict_1003_unitmbart.txt): 1,007\n"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2FeatureExtractor.from_pretrained(hf_path)\n",
    "model, cfg, task = fairseq.checkpoint_utils.load_model_ensemble_and_task(\n",
    "    [fairseq_wav2vec2_path], arg_overrides={\"data\": \"./\", \"task\": \"speech_to_text\"}\n",
    ")\n",
    "hf_model = SpeechToSpeechModel.from_pretrained(hf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9ce51ed-7658-4266-a927-4cec25b86f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model[0].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e83324a-60f7-4fee-a469-218a36745f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    fsq_output = model.decoder.forward(prev_output_tokens=torch.arange(10).reshape(1, 10))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14fb7834-8b81-4fe9-b9ca-2eed578329e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    hf_output = hf_model.decoder(torch.arange(10).reshape(1, 10)).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa8aca6-35df-4d83-99a3-6e663e2e4ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hf_output.shape == fsq_output.shape, f\"Shapes don't match. Got {hf_output.shape} for HF and {fsq_output.shape} for fsq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8b0a6a9-4a5d-4d45-9eab-5d88af42f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(hf_output[:, 0, :], fsq_output[:, 0, :], atol=1e-4), f\"Values don't match. Max diff={torch.max(torch.abs(hf_output - fsq_output))}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90373565-3e77-4609-9e07-e5c43bdc9fab",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Values don't match. Max diff=0.03824864700436592",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(hf_output[:, \u001b[38;5;241m6\u001b[39m, :], fsq_output[:, \u001b[38;5;241m6\u001b[39m, :], atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValues don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match. Max diff=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mabs(hf_output \u001b[38;5;241m-\u001b[39m fsq_output))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Values don't match. Max diff=0.03824864700436592"
     ]
    }
   ],
   "source": [
    "assert torch.allclose(hf_output[:, 1, :], fsq_output[:, 1, :], atol=1e-2), f\"Values don't match. Max diff={torch.mean(torch.abs(hf_output - fsq_output))}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35f831a9-9c94-46f1-ad46-8dc933592d25",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Values don't match. Max diff=1.0779876708984375",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(hf_output, fsq_output, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValues don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match. Max diff=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39mabs(hf_output \u001b[38;5;241m-\u001b[39m fsq_output))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Values don't match. Max diff=1.0779876708984375"
     ]
    }
   ],
   "source": [
    "assert torch.allclose(hf_output, fsq_output, atol=1e-2), f\"Values don't match. Max diff={torch.max(torch.abs(hf_output - fsq_output))}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f22d2e6-07c5-4185-a5d4-d1a6dbf4f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fariseq positional embeddings for tokens 0 to 10\n",
    "0 tensor([0.9093, 0.9236, 0.9365,  ..., 1.0000, 1.0000, 1.0000])\n",
    "1 tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
    "2 tensor([0.1411, 0.1939, 0.2453,  ..., 1.0000, 1.0000, 1.0000])\n",
    "3 tensor([-0.7568, -0.7082, -0.6570,  ...,  1.0000,  1.0000,  1.0000])\n",
    "4 tensor([-0.9589, -0.9804, -0.9939,  ...,  1.0000,  1.0000,  1.0000])\n",
    "5 tensor([-0.2794, -0.3805, -0.4756,  ...,  1.0000,  1.0000,  1.0000])\n",
    "6 tensor([0.6570, 0.5578, 0.4520,  ..., 1.0000, 1.0000, 1.0000])\n",
    "7 tensor([0.9894, 1.0000, 0.9906,  ..., 1.0000, 1.0000, 1.0000])\n",
    "8 tensor([0.4121, 0.5527, 0.6768,  ..., 1.0000, 1.0000, 1.0000])\n",
    "9 tensor([-0.5440, -0.3863, -0.2194,  ...,  1.0000,  1.0000,  1.0000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba96ca-18c5-48eb-8517-52ef18fa5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HF positional embeddings for tokens 0 to 10\n",
    "0 tensor([0., 0., 0.,  ..., 1., 1., 1.])\n",
    "1 tensor([0.8415, 0.8317, 0.8219,  ..., 1.0000, 1.0000, 1.0000])\n",
    "2 tensor([0.9093, 0.9236, 0.9364,  ..., 1.0000, 1.0000, 1.0000])\n",
    "3 tensor([0.1411, 0.1938, 0.2451,  ..., 1.0000, 1.0000, 1.0000])\n",
    "4 tensor([-0.7568, -0.7083, -0.6572,  ...,  1.0000,  1.0000,  1.0000])\n",
    "5 tensor([-0.9589, -0.9804, -0.9939,  ...,  1.0000,  1.0000,  1.0000])\n",
    "6 tensor([-0.2794, -0.3803, -0.4752,  ...,  1.0000,  1.0000,  1.0000])\n",
    "7 tensor([0.6570, 0.5580, 0.4524,  ..., 1.0000, 1.0000, 1.0000])\n",
    "8 tensor([0.9894, 1.0000, 0.9907,  ..., 1.0000, 1.0000, 1.0000])\n",
    "9 tensor([0.4121, 0.5524, 0.6764,  ..., 1.0000, 1.0000, 1.0000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
